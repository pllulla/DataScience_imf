{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PANDAS\n",
    "\n",
    "Importamos la librería pandas para poder trabajar con DataFrames en Python, en caso de que no venga instalada por defecto podemos realizar lo siguiente:\n",
    "* <code>pip install pandas</code>\n",
    "* <code>conda install pandas</code>\n",
    "* <code>conda install -c anaconda pandas </code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos pandas, utilizaremos el alias para denominar a cada función de pandas 'pd'\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "\n",
    "Se trata de una colección indexada que funciona de un modo similar a un diccionario de datos, es la unidad mínima con la que podemos trabajar en Pandas, de hecho, un Dataframe no es más que una sucesión de series.\n",
    "\n",
    "Debemos tener en cuenta que las series funcionan de forma similar a un diccionario de datos donde tenemos los archivos formados por {clave_1: 'valor uno', clave_2. 'valor dos', ....., clave_n: 'valor m'}. Las series pueden formarse a través de un numpy array o una lista y unos valores que actuarán como índices (si no se introducen se tomarán por defecto de 0 a la longitud del conjunto de elementos).\n",
    "\n",
    "Para crear una serie, simplemente utilizaremos la función <code>**Series**</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bitcoin     15613.77\n",
       "Ethereum      496.29\n",
       "XRP             0.52\n",
       "Tether          0.83\n",
       "BTC Cash      242.03\n",
       "dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criptos = pd.Series(\n",
    "    [15613.77, 496.29, 0.52, 0.83, 242.03], \n",
    "    index= ['Bitcoin', 'Ethereum', 'XRP', 'Tether', 'BTC Cash']\n",
    ")\n",
    "\n",
    "criptos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las seires tienen su propio tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(criptos) # Clase Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bitcoin     15613.77\n",
       "Ethereum      496.29\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criptos[0: 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criptos['Bitcoin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta.\n",
    "\n",
    "Un objeto `pandas.Series` al ser similar a un diccionario de datos, ¿posee funciones similares a un diccionario de datos como `.keys()`o, `.values()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframes\n",
    "\n",
    "La función principal que nos permite pasar prácticamente cualquier tipo de variable (lista, array, diccionario de datos...) es:\n",
    "* <code>__pandas.DataFrame()__</code>\n",
    "\n",
    "Veremos cómo crear DataFrames desde diferentes estructuras de datos.\n",
    "\n",
    "* A través de **Series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un Dataframe a través del objeto Series\n",
    "df_criptos = pd.DataFrame(criptos)\n",
    "\n",
    "# Vemos que por defecto, se genera una columna con nombre 0, \n",
    "# ya que no se lo hemos especificado.\n",
    "df_criptos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A través de **Numpy Array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 2 a través numpy array\n",
    "import numpy as np\n",
    "\n",
    "# Creamos un array de 5 número aleatorios\n",
    "array_uno = np.random.rand(5)\n",
    "\n",
    "pd.DataFrame(array_uno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importante destacar en el ejemplo anterior, que al no utilizar ningún parámetro como índice, automáticamente ha tomado valores de 0 a n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A través de **Listas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 3 listas\n",
    "\n",
    "# Creamos una lista\n",
    "lista = ['hola mundo', 1, 3.14, 'adios']\n",
    "\n",
    "# Pasamos la lista a un DataFrame\n",
    "df_list = pd.DataFrame(lista)\n",
    "\n",
    "df_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A través de un **diccionario de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 4 Diccionario de datos\n",
    "\n",
    "# Creamos un Diccionario de datos\n",
    "dict_cli = {'ID001': 'Cliente uno',\n",
    "            'ID002': 'Cliente dos',\n",
    "            'ID003': 'Cliente tres',\n",
    "            'ID004': 'Cliente cuatro',\n",
    "            'ID005': 'Cliente cinco'}\n",
    "\n",
    "dict_cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasamos el dict a un DataFrame\n",
    "\n",
    "df_dict = pd.DataFrame.from_dict(dict_cli, orient='index')\n",
    "\n",
    "df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que cuando se trata de un diccionario de datos, tenemos que utilizar el parámetro **orient** para que reconozca correctamente el campo clave como índice. De lo contrario, podemos utilizar el parámetro **index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n",
    "\n",
    "Tomando la siguiente lista como referencia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calificaciones = [\n",
    "    ('Alberto', 4),\n",
    "    ('Noelia', 7.25),\n",
    "    ('Marcos', 9),\n",
    "    ('Guillermo', 5.25)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea un dataframe a través de la lista.\n",
    "\n",
    "#### Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando archivos a través de un CSV\n",
    "\n",
    "Una de las grandes ventajas que supone trabajar con DataFrames es que podemos cargar archivos muy fácilmente y poder procesar sus filas y columnas. Hay varios tipos de datos que podemos cargar a pandas:\n",
    "\n",
    "* CSV\n",
    "* JSON\n",
    "* HTML\n",
    "* EXCEL\n",
    "* HDF5\n",
    "* TXT\n",
    "* ORC\n",
    "* STATA\n",
    "* ...\n",
    "\n",
    "Todos los tipos de datos que podemos cargar se encuentran en el siguiente link: https://pandas.pydata.org/docs/user_guide/io.html#io\n",
    "\n",
    "A lo largo del contenido mostraremos las principales funcionalidades de los dataframes desde csv como dataframe.\n",
    "\n",
    "Para cargar un csv como un Dataframe disponemos de la función </code>**read_csv**</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses = pd.read_csv('housing_California.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>-121.09</td>\n",
       "      <td>39.48</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>1.5603</td>\n",
       "      <td>78100.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>-121.21</td>\n",
       "      <td>39.49</td>\n",
       "      <td>18.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>2.5568</td>\n",
       "      <td>77100.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>-121.22</td>\n",
       "      <td>39.43</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2254.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>1.7000</td>\n",
       "      <td>92300.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>-121.32</td>\n",
       "      <td>39.43</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>1.8672</td>\n",
       "      <td>84700.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>-121.24</td>\n",
       "      <td>39.37</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2785.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>2.3886</td>\n",
       "      <td>89400.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0        -122.23     37.88                41.0        880.0           129.0   \n",
       "1        -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2        -122.24     37.85                52.0       1467.0           190.0   \n",
       "3        -122.25     37.85                52.0       1274.0           235.0   \n",
       "4        -122.25     37.85                52.0       1627.0           280.0   \n",
       "...          ...       ...                 ...          ...             ...   \n",
       "20635    -121.09     39.48                25.0       1665.0           374.0   \n",
       "20636    -121.21     39.49                18.0        697.0           150.0   \n",
       "20637    -121.22     39.43                17.0       2254.0           485.0   \n",
       "20638    -121.32     39.43                18.0       1860.0           409.0   \n",
       "20639    -121.24     39.37                16.0       2785.0           616.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "0           322.0       126.0         8.3252            452600.0   \n",
       "1          2401.0      1138.0         8.3014            358500.0   \n",
       "2           496.0       177.0         7.2574            352100.0   \n",
       "3           558.0       219.0         5.6431            341300.0   \n",
       "4           565.0       259.0         3.8462            342200.0   \n",
       "...           ...         ...            ...                 ...   \n",
       "20635       845.0       330.0         1.5603             78100.0   \n",
       "20636       356.0       114.0         2.5568             77100.0   \n",
       "20637      1007.0       433.0         1.7000             92300.0   \n",
       "20638       741.0       349.0         1.8672             84700.0   \n",
       "20639      1387.0       530.0         2.3886             89400.0   \n",
       "\n",
       "      ocean_proximity  \n",
       "0            NEAR BAY  \n",
       "1            NEAR BAY  \n",
       "2            NEAR BAY  \n",
       "3            NEAR BAY  \n",
       "4            NEAR BAY  \n",
       "...               ...  \n",
       "20635          INLAND  \n",
       "20636          INLAND  \n",
       "20637          INLAND  \n",
       "20638          INLAND  \n",
       "20639          INLAND  \n",
       "\n",
       "[20640 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "\n",
    "Lee el archivo 'compras_uno.csv' como dataframe\n",
    "\n",
    "#### Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "\n",
    "Lee el archivo 'compras_dos.csv' como dataframe\n",
    "\n",
    "#### Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4\n",
    "\n",
    "Lee el archivo 'compras_tres.csv' como dataframe\n",
    "\n",
    "#### Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5\n",
    "\n",
    "Lee de nuevo el archivo 'housing_California.csv' como dataframe, utiliza el parámetro `header=None`\n",
    "\n",
    "#### Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 6\n",
    "\n",
    "Lee de nuevo el archivo 'housing_California.csv' como dataframe, utiliza el parámetro `header=[0,1,2]`\n",
    "\n",
    "#### Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 7\n",
    "\n",
    "\n",
    "Carga el dataset 'housing_California.csv', cargando solamente las columnas housing_median_age y population\n",
    "\n",
    "#### Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>322.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>2401.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>558.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>565.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>25.0</td>\n",
       "      <td>845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>18.0</td>\n",
       "      <td>356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>18.0</td>\n",
       "      <td>741.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1387.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       housing_median_age  population\n",
       "0                    41.0       322.0\n",
       "1                    21.0      2401.0\n",
       "2                    52.0       496.0\n",
       "3                    52.0       558.0\n",
       "4                    52.0       565.0\n",
       "...                   ...         ...\n",
       "20635                25.0       845.0\n",
       "20636                18.0       356.0\n",
       "20637                17.0      1007.0\n",
       "20638                18.0       741.0\n",
       "20639                16.0      1387.0\n",
       "\n",
       "[20640 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ej_7 = pd.read_csv('housing_California.csv', usecols=['housing_median_age', 'population'])\n",
    "\n",
    "ej_7 # Con usecols podemos definir las columnas que necesitemos cargar en el momento de lectura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de Series y Columnas de un dataframe.\n",
    "\n",
    "Tal y como hemos visto antes un dataframe es una sucesión o colección de series, es decir, que cada columna actúa como una serie ya que todas las columnas comparten el mismo índice. \n",
    "\n",
    "Para acceder a una columna tenemos que escribir entre corchetes el nombre de la misma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        41.0\n",
       "1        21.0\n",
       "2        52.0\n",
       "3        52.0\n",
       "4        52.0\n",
       "         ... \n",
       "20635    25.0\n",
       "20636    18.0\n",
       "20637    17.0\n",
       "20638    18.0\n",
       "20639    16.0\n",
       "Name: housing_median_age, Length: 20640, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses['housing_median_age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si atendemos al tipo de clase que tiene una columna veremos que es Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(houses['housing_median_age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma de acceder a las columnas de un dataframe es:\n",
    "\n",
    "* nombre_df.__nombre_columna__ (sin las comillas de string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        41.0\n",
       "1        21.0\n",
       "2        52.0\n",
       "3        52.0\n",
       "4        52.0\n",
       "         ... \n",
       "20635    25.0\n",
       "20636    18.0\n",
       "20637    17.0\n",
       "20638    18.0\n",
       "20639    16.0\n",
       "Name: housing_median_age, Length: 20640, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses.housing_median_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de múltiples columnas\n",
    "\n",
    "Ahora que ya hemos visto como un DataFrame se compone de Series, podemos ver cómo seleccionar varias columnas. Para ello, simplemente tenemos que encerrar entre corchetes los nombres de las columnas que queremos seleccionar como:\n",
    "\n",
    "__nombre_df[['columna_uno', 'columna_dos', 'columna_tres']]__\n",
    "\n",
    "Análogamente, podremos pasar una lista con nombres de las columnas.\n",
    "\n",
    "Para realizar lo mismo mediante indexación, es decir, obtener un subconjunto de columnas del dataframe por la posición que ocupan las columnas podemos hacer:\n",
    "* __nombre_dataframe[nombre_dataframe.columns[[col_n, col_m]]]__\n",
    "* __nombre_dataframe.iloc[:, [col_n, col_m]]__\n",
    "\n",
    "Mediante nombres de columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses[['housing_median_age', 'total_bedrooms']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['housing_median_age', 'total_bedrooms', 'population']\n",
    "houses[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante índices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.columns[0: 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses[houses.columns[2:6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para seleccionar varias columnas con iloc, tenemos que tener en cuenta que un dataframe se distribuye de la siguiente manera.\n",
    "\n",
    "* __dataframe[filas, columnas]__: En donde tanto filas como columnas son indexables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.iloc[:,[1,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# houses.iloc[:,['latitude', 'total_rooms']] # Solo funciona con números"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de múltiples filas de un dataframe\n",
    "\n",
    "Por lo general, podemos utilizar las mismas propiedades que las de las listas, salvo seleccionar una única fila que es diferente:\n",
    "* Para seleccionar desde la primera fila hasta un límite realizamos: <code>__dataframe[0:n]__</code>, análogamente podemos omitir el cero y realizar simplemente: <code>__dataframe[ :n]__</code>\n",
    "* Para seleccionar desde una fila hasta el final realizamos: <code>__dataframe[n:]__</code>\n",
    "* Para seleccionar un rango definido de filas realizamos: <code>__dataframe[n:m]__</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos de la fila 0 a la 2\n",
    "houses[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que es lo mismo si quitamos el cero.\n",
    "houses[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos de fila n al final\n",
    "houses[20635:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rango personalizado, escogemos de fila 150 a 200\n",
    "houses[150:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para seleccionar una sola fila no podemos hacer la misma operación que en las listas, indexar una única posición <code>lista[n]</code>, ya que esto no nos devuelve nada, para ello, tenemos que seleccionar como un rango personalizado la fila que queremos mostrar más una posición <code>dataframe[n:n+1]</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses[1000:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses[1000:1001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen función iloc\n",
    "\n",
    "Con la función __.iloc__ podemos seleccionar varias filas de una forma muy sencilla que puede resumirse como:\n",
    "* <code>dataframe.iloc[0]</code> - Primera fila de un dataframe.\n",
    "* <code>dataframe.iloc[1]</code> - Segunda fila de un dataframe.\n",
    "* <code>dataframe.iloc[-1]</code> - (Indexación negativa) Última fila de un dataframe\n",
    "* <code>dataframe.iloc[[n]]</code> - Fila _n_ del dataframe.\n",
    "* <code>dataframe.iloc[n:m]</code> - Rango personalizado de las filas _n_ a _m_\n",
    "\n",
    "En columnas el resumen de la función __.iloc__ pasaría a ser:\n",
    "* <code>dataframe.iloc[:, 0]</code> - Primera columna de un dataframe.\n",
    "* <code>dataframe.iloc[:, 1]</code> - Segunda columna de un dataframe.\n",
    "* <code>dataframe.iloc[-1]</code> - (Indexación negativa) Última columna de un dataframe\n",
    "* <code>dataframe.iloc[:,[n,m]]</code> - Exactamente, las columnas _n_ y _m_ de un dataframe.\n",
    "* <code>dataframe.iloc[:, n:m]</code> - Rango personalizado de las columnas _n_ a _m_ de un dataframe.\n",
    "\n",
    "Podemos también realizar una selección múltiple de columnas filas con __.iloc__ con los siguientes ejemplos:\n",
    "* <code>dataframe.iloc[[0,5,7,9], [1,4]]</code> - Selección de las filas 0,5,7,9 de las columnas 1 y 4\n",
    "* <code>dataframe.iloc[0:10, 0:2]</code> - Selección basada en rangos de las filas 0 a 10 de las columnas 0 a 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.iloc[[20,5680,19875], [3, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.iloc[0:10, 0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Índices de un DataFrame\n",
    "\n",
    "Se tratan de las posiciones que ocupa cada fila dentro de un dataframe, a no ser que se especifique un tipo de índice concreto basado en etiquetas, los índices serán de 0 a la longitud total del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un dataframe\n",
    "ventas = {\n",
    "   'region': [\"EUROPA\", \"EUROPA\", \"EUROPA\", \n",
    "              \"USA\", \"USA\", \"USA\", \"LATAM\", \"LATAM\"],\n",
    "   'ventas':[153752, 168742, 162587, 256198, 285743, 290371, 145638, 151678],\n",
    "   'anio':[2018, 2019, 2020, 2018, 2019, 2020, 2018, 2019]\n",
    "}\n",
    "df = pd.DataFrame(ventas)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para observar el índice de un dataframe podemos hacer uso de su atributo <code>**index**</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependiendo de cómo estén formados nuestros datos, vamos a poder crear multi índices basados en columnas propias de nuestro dataframe, si nos fijamos la columna region y anio tienen elementos repetidos. Esto nos permitirá hacer multi-índices donde tengamos un continente por año de ventas.\n",
    "\n",
    "Con la función <code> set_index()</code> vamos a poder establecer un nuevo índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_year = df.set_index([\"region\", \"anio\"])\n",
    "region_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En vista del nuevo dataframe, podemos ver que ahora las columnas region y anio actúan como índice, por lo que si consultamos la primera fila..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_year.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos el dato que pertenece al volumen de ventas, siendo region (Europe) y el año (2018) sus índices\n",
    "\n",
    "Del mismo modo, podemos pasar una lista como índice a un dataframe. Obviamente, esta lista debe ser de la misma longitud que el dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = ['REGISTRO_1', 'REGISTRO_2', 'REGISTRO_3', 'REGISTRO_4', \n",
    "          'REGISTRO_5', 'REGISTRO_6', 'REGISTRO_7', 'REGISTRO_8']\n",
    "\n",
    "df.index = indice\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la función <code>.loc</code> podemos buscar elementos en el índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['REGISTRO_6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 8\n",
    "\n",
    "Crea un nuevo dataframe que contenga la siguiente información.\n",
    "\n",
    "* Se van a introducir datos de las asignatura de Matemáticas un alumno.\n",
    "* Para la asignatura se solicitará al usuario la calificación obtenida\n",
    "* Se preguntará al usuario desde que año a que año se va a consultar la información\n",
    "* Se tomarán como índice los años de dichas calificaciones\n",
    "\n",
    "#### Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solicitamos los años\n",
    "\n",
    "año_inicio = int(input('Introduce el primer año para consultar datos --> '))\n",
    "año_fin = int(input('Introduce el último año para consultar datos --> '))\n",
    "\n",
    "while not año_fin > año_inicio:\n",
    "    print('El último año debe ser mayor que el de inicio')\n",
    "    año_inicio = int(input('Introduce el primer año para consultar datos --> '))\n",
    "    año_fin = int(input('Introduce el último año para consultar datos --> '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Años seleccionados desde: {}, hasta: {}'.format(año_inicio, año_fin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solicitamos las calificaciones\n",
    "\n",
    "anios = range(año_inicio, año_fin+1)\n",
    "\n",
    "calificaciones_matematicas = []\n",
    "\n",
    "# Recorremos los años\n",
    "for anio in anios:\n",
    "    nota_mates = float(input('Introduce la nota en matemáticas para el año ' + str(anio) + ': ' ))\n",
    "    calificaciones_matematicas.append(nota_mates)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Las calificaciones son ', calificaciones_matematicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el dataframe\n",
    "\n",
    "calificaciones = {\n",
    "   'anio': anios,\n",
    "   'calificaciones': calificaciones_matematicas\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calificaciones = pd.DataFrame(calificaciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calificaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calificaciones.index = calificaciones.anio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calificaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algunas funciones básicas de un dataframe\n",
    "\n",
    "A continuación, vamos a ver un listado de algunas de las principales funciones que podemos aplicar en un dataframe para operar en sus columnas:\n",
    "\n",
    "* Obtener las primeras filas de un dataframe con __<code>.head</code>__\n",
    "* Obtener las últimas filas de un dataframe con __<code>.tail</code>__\n",
    "* Obtener los elmentos únicos de una columna de un dataframe con __<code>.unique</code>__\n",
    "* Obtener la frecuencia de los valores únicos de una columna de un dataframe __<code>.value_counts</code>__\n",
    "* Obtener un resumen estadístico del dataset con __<code>.describe</code>__\n",
    "* Obtener la media de una columna con __<code>.mean</code>__\n",
    "* Obtener una copia de un dataframe con __<code>.copy</code>__\n",
    "* Ver los nombres de las columnas de un dataframe con __<code>.columns</code>__\n",
    "* Obtener la correlación entre todas las variables numéricas con __<code>.corr</code>__\n",
    "* Borrar duplicados de un dataframe con __<code>.drop_duplicates</code>__\n",
    "* Especialmente para Big Data sets podemos ver el consumo en memoria RAM de nuestro dataset con __<code>.memory_usage</code>__\n",
    "* Ver un resumen resumen gráfico (basado en densidad, scatter plots y gráficas de correlaciones) de todas las variables del dataframe con __<code>.scatter_matrix</code>__\n",
    "* Obtener un histograma de cada variable numérica del dataset con __<code>.hist</code>__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeras filas de un Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeras filas del dataframe\n",
    "houses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si en .head() no especificamos nada, por defecto, se muestran 5, podemos especificar el número de filas a mostrar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Últimas filas de un Dataframe\n",
    "\n",
    "Lo mismo pasa con el comando __tail__, si no le pasamos como parámetro el número de filas a visualizar, tomará las últimas 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores únicos por columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos los valores únicos de la columna \n",
    "houses['ocean_proximity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses['latitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses['ocean_proximity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos comprobar esta es una función que tiene un mayor impacto en variables categóricas, ya por lo general, las variables numéricas tienen demasiados valores diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen estadístico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen estadístico.\n",
    "houses.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es interesante observar que el resumen estadístico descarta automáticamente cualquier variable que no sea numérica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Media de una columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Media de la variable total rooms', round(houses['total_rooms'].mean(), 3))\n",
    "print('Media de la variable total bedrooms', round(houses['total_bedrooms'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copia de un dataframe\n",
    "\n",
    "Al igual que en listas y arrays los dataframes comparten memoria. Es fácil equivocarnos y asignar a una nueva variable un dataframe completo, posteriormente, en esta nueva variable realizar modificaciones, pensando que sólamente las estamos realizando en la copia del dataframe, pero no es así, estamos realizando modificaciones en ambos dataframes ya que al estar almacenados en memoria, comparten las mismas posiciones, veamos un ejemplo de como NO copiar un dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_copy = houses\n",
    "\n",
    "# Modificamos la primera fila por ceros\n",
    "bad_copy.iloc[[0]] = np.zeros(len(houses.columns))\n",
    "\n",
    "bad_copy.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que los cambios se reflejan en el dataframe original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, hemos modificado ambos dataframes, para únicamente realizar modificaciones sobre la copia, hemos de hacer uso del comando <code>.copy</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses = pd.read_csv('housing_California.csv')\n",
    "\n",
    "# Copiamos correctamente el dataframe\n",
    "df_copia = houses.copy()\n",
    "\n",
    "df_copia.iloc[[0]] = np.zeros(len(houses.columns))\n",
    "\n",
    "df_copia.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlaciones de las variables numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que automáticamente toma todas las variables numéricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombres de las columnas de un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.columns[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas de un dataframe pueden trabajarse como listas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borrar duplicados de un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para verlo más claro, vamos a realizar una copia de las diez primeras posiciones del data frame\n",
    "ten_rows = houses.head(10).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicamos la fila 9 varias veces\n",
    "ten_rows = ten_rows.append(ten_rows.iloc[[9]])\n",
    "ten_rows = ten_rows.append(ten_rows.iloc[[9]])\n",
    "ten_rows = ten_rows.append(ten_rows.iloc[[9]])\n",
    "ten_rows = ten_rows.append(ten_rows.iloc[[9]])\n",
    "ten_rows = ten_rows.append(ten_rows.iloc[[9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_rows = ten_rows.drop_duplicates(inplace = False, keep = 'first')\n",
    "ten_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso de RAM para un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumo RAM del dataframe en BYTES\n",
    "houses.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis gráfico con scatter matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración para mostrar gráficas en notebook\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Importamos scatter_matrix\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# Es necesario que configuremos el tamaño de las gráficas que será el mismo que el número de columnas\n",
    "scatter_matrix(houses, figsize = (len(houses.columns), \n",
    "                                  len(houses.columns)), \n",
    "               diagonal = 'kde');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramas de las variables numéricas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas de cada variable continua del dataframe.\n",
    "houses.hist(figsize = (len(houses.columns), len(houses.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambiando el tipo de las variables.\n",
    "\n",
    "Con la función `info` podemos obtener la información del tipo de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos comprobar, todas las variables son de tipo float, excepto ocean_proximity que es de tipo object, cuando la realidad es que esto, no es así, algunas de las transformaciones más importantes que podemos realizar en un dataframe sobre sus variables es cambiarles el tipo, es decir que pasen a ser categóricas o tipo fecha, vamos a ver cómo cambiar a tipo categórica las variables de un dataframe.\n",
    "\n",
    "Una de las posibles formas de cambiar el tipo de una variable es a través de `pd.Categorical`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses[\"ocean_proximity\"] = pd.Categorical(houses[\"ocean_proximity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos la información del dataframe de nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, podemos mostrar un resumen estadístico solamente de las variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.describe(include='category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AGRUPACIÓN DE DATAFRAMES - GROUP BY\n",
    "\n",
    "Al igual que en SQL, desde Python también podemos realizar agrupaciones de nuestros datos con la función __<code>groupby</code>__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupamos por la media de los valores numéricos para la columna ocean_proximity\n",
    "houses.groupby(['ocean_proximity']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos cuántos tipos el total de dormitorios en función de\n",
    "# su frecuencia.\n",
    "houses.groupby(['total_bedrooms']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.groupby(['total_bedrooms']).count()['ocean_proximity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el porcentaje de valores para una variable categórica\n",
    "print((pd.crosstab(index=houses[\"ocean_proximity\"], columns=\"count\"))/len(houses) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MERGE DE DATAFRAMES\n",
    "\n",
    "En algunas ocasiones, vamos a necesitar unir dos o más datasets para ello, en primer lugar, al igual que con listas, podemos hacer uso de la función __<code>.append</code>__\n",
    "\n",
    "Debido a la dimensión de filas y columnas del dataframe, vamos a crear dos dataframes más reducidos para poder ejemplificar correctamente la función append."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos datasets reducidos\n",
    "first_positions = houses[['housing_median_age', \n",
    "                             'total_rooms', \n",
    "                             'total_bedrooms']].head(5).copy()\n",
    "\n",
    "\n",
    "last_positions = houses[['housing_median_age', \n",
    "                             'total_rooms', \n",
    "                             'total_bedrooms']].tail(4).copy()\n",
    "\n",
    "print(first_positions.shape)\n",
    "print(last_positions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos ambos datasets con append\n",
    "first_positions = first_positions.append(last_positions)\n",
    "\n",
    "print(first_positions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante que tengamos en cuenta con la presencia de nuevas columnas que aparezcan solamente en uno de los dataframes que vayamos a concatenar. Para ejemplificarlo, vamos a obtener de nuevo los datasets, dando una columna a más al dataset con las últimas posiciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos datasets reducidos\n",
    "first_positions = houses[['housing_median_age', \n",
    "                             'total_rooms', \n",
    "                             'total_bedrooms']].head(5).copy()\n",
    "\n",
    "\n",
    "last_positions = houses[['housing_median_age', \n",
    "                             'total_rooms', \n",
    "                             'total_bedrooms',\n",
    "                             'households']].tail(4).copy()\n",
    "\n",
    "print(first_positions.shape)\n",
    "print(last_positions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos ambos datasets con append\n",
    "first_positions = first_positions.append(last_positions)\n",
    "\n",
    "first_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En segundo lugar, podemos hacer uso de la función __<code>.concat</code>__. Es muy importante saber los tipos de unión ( _join_ ) que podemos realizar al concatenar datasets\n",
    "* __inner__: Se realiza la unión por los elementos comunes de ambos datasets.\n",
    "* __outer__: La unión se realiza por todos los elementos entre los datasets\n",
    "    \n",
    "Se recomienda echar un vistazo a la documentación para ver los diferentes tipos de join que podemos realizar. https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_positions = houses[['housing_median_age', \n",
    "                             'total_rooms', \n",
    "                             'total_bedrooms',\n",
    "                             'ocean_proximity']].head(5).copy()\n",
    "\n",
    "\n",
    "last_positions = houses[['housing_median_age', \n",
    "                             'total_rooms', \n",
    "                             'total_bedrooms',\n",
    "                             'households',\n",
    "                             'ocean_proximity']].tail(4).copy()\n",
    "\n",
    "union_outer = pd.concat([first_positions, last_positions], \n",
    "                        ignore_index=True, join='outer')\n",
    "\n",
    "union_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_inner = pd.concat([first_positions, last_positions], \n",
    "                        ignore_index=True, join='inner')\n",
    "\n",
    "union_inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compo podemos ver en el merge por tipo _inner_ la columna _households_ del nuevo dataset no aparece ya que no es un elemento común entre ambos datasets. No obstante hemos de tener en cuenta que si un dataset no tiene filas pertenecientes a una columna de otro dataset como es el caso de la columna _households_ que únicamente aparece en el nuevo dataset. Sus valores, pasarán a ser nulos.\n",
    "\n",
    "### NUEVAS COLUMNAS\n",
    "\n",
    "En muchas ocasiones, vamos a necesitar añadir nuevas columnas a un dataframe o realizar modificaciones entre las columnas de un dataframe para obtener una nueva. Es importante saber que las operaciones se realizan de forma columnar, es decir, si dos columnas tienen una misma longitud podemos realizar una operación entre ambas si necesidad de iterara sobre sus filas.\n",
    "\n",
    "Para agregar una nueva columna simplemente podemos crear una nueva variable con el nombre del dataframe y el nombre de la columna que vamos a crear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(65, 120, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_inner['area'] = np.random.randint(65, 120, len(union_inner))\n",
    "\n",
    "print(union_inner.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_inner.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos crear una nueva columna que sea la media de camas por habitaciones totales\n",
    "\n",
    "union_inner['mean_bedrooms'] = round(union_inner['total_rooms'] / union_inner['total_bedrooms'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BORRADO DE FILAS Y COLUMNAS\n",
    "\n",
    "En algunas ocasiones, cuando realicemos limpieza de datos o, porque no sean objeto de nuestro análisis vamos a necesitar borrar filas o columnas de un dataframe, para ambos casos la función es la misma __<code>.drop</code>__, si el borrado queremos realizarlo para filas usaremos en el parámetro __axis__ el valor 0 y para las columnas el valor 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_inner = union_inner.drop(['housing_median_age', 'mean_bedrooms'], axis = 1)\n",
    "\n",
    "union_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrado por filas\n",
    "print('TODAS LAS FILAS')\n",
    "print(union_inner, \"\\n\")\n",
    "\n",
    "union_inner = union_inner.drop(3, axis=0)\n",
    "\n",
    "print('BORRADO DE FILA 3')\n",
    "print(union_inner.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GESTIÓN DE NULOS\n",
    "\n",
    "Finalmente, como es habitual cuando trabajamos con dataframes pueden aparecer los _missing values_ o simplemente, valores nulos, en Python representados por el string __NaN__, mediante la función __<code>.isnull</code>__ podremos saber si un elemento de un dataframe es nulo o no, una práctica muy habitual es obtener el número de valores nulos por columna en un dataframe y su porcentaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*CANTIDAD de datos nulos por columna en el dataframe\")\n",
    "print(union_outer.isnull().sum())\n",
    "print(\"----------------------------------\")\n",
    "print(\"*PORCENTAJE de datos nulos por columna en el dataframe\")\n",
    "print(union_outer.isnull().sum()/len(union_outer)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo que queremos es reemplazar los valores nulos y no borrarlos haremos uso de la función __<code>.fillna</code>__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_outer['households'] = union_outer['households'].fillna(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*CANTIDAD de datos nulos por columna en el data frame\")\n",
    "print(union_outer.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por el contrario, si lo que queremos es borrar los valores nulos de un dataframe podemos hacer uso de la función __<code>.dropna</code>__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_outer = pd.concat([first_positions, last_positions], \n",
    "                        ignore_index=True, join='outer', sort=False)\n",
    "\n",
    "union_outer = union_outer.dropna()\n",
    "\n",
    "print(\"*CANTIDAD de datos nulos por columna en el data frame\")\n",
    "print(union_outer.isnull().sum())\n",
    "\n",
    "print(union_outer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_outer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escribiendo dataframe como csv\n",
    "\n",
    "Al igual que podemos cargar datos de diferentes fuentes de datos y procesarlos como un dataframe, también podemos posteriormente escribir un dataframe en una de las múltiples fuentes que acepta pandas para exportar archivos, en esta ocasión, volcaremos la información de un dataframe como un .csv, para ello, disponemos de la función <code>**to_csv**</code>. Como parámetros utilizaremos, el nombre del archivo, el argumento __sep__ para utilizar un tipo de separador u otro y, si no queremos que se muestre el índice del dataframe, utilizaremos el argumento __index__ con valor _none_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_outer.to_csv('RESULTADOS.csv', sep=',', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 8\n",
    "\n",
    "Se utilizará una base de datos (en .csv) procedente de la web https://openflights.org/data.html , el dataset contiene la siguiente información:\n",
    "* **AirportID**: Identificador de cada vuelo para un aeropuerto.\n",
    "* **Name**: Nombre del aeropuerto.\n",
    "* **City**: Ciudad en la que se encuentra el aeropuerto.\n",
    "* **Country**: País o territorio en el que se encuentra el aeropuerto.\n",
    "* **IATA**: Código de asociación internacional de transporte aéreo, código del aeorpuerto.\n",
    "* **ICAO**: Código de organización civil internacional, código de aeoropuertto.\n",
    "* **Latitude**: Coordenada del aeropuerto (latitud).\n",
    "* **Longitude**: Coordenada del aeropuerto (longitud).\n",
    "* **Altitude**: Altitud del aeropuerto (en pies).\n",
    "* **Timezone**: Zona horaria.\n",
    "* **DST**: Código referente al continente (Daylight savings time). Europe (E), A (US/CANADA), S (South America), O (Australia), Z (New Zeeland), N (None), U (Unknown).\n",
    "* **Tz**: Zona horaria del aeropuerto. Por ejemplo: (America/Los_Angeles).\n",
    "* **Type**: Tipo de aeropuerto: airport, station, port, unknown.\n",
    "* **Source**: Fuente de datos.\n",
    "\n",
    "Con la información del dataset realizar lo siguiente: \n",
    "* 1 Carga del dataset como dataframe.\n",
    "* 2 Muestra las primeras 10 filas del dataframe.\n",
    "* 3 Obtén un resumen estadístico.\n",
    "* 4 Para este análisis no vamos a emplear las columnas 'AirportID', 'Latitude', 'Longitude' y 'Altitude', elimínalas del dataframe.\n",
    "* 5 Vuelve a obtener un resumen estadístico, ¿de qué forma han cambiado los datos?.\n",
    "* 6 Sobre el resumen estadístico anterior parece que en la columna TZ hay un valor raro \\N, revisa la proporción de los mismos con value_counts.\n",
    "* 7 Vuelve a cargar el dataset de modo que se interpreten correctamente los valores nulos (repite el apartado 4, borra las columnas).\n",
    "* 8 Revisa los valores nulos de todo el dataframe.\n",
    "* 9 Sobrescribe los valores nulos de las columnas IATA e ICAO por el valor 'DESCONOCIDO'\n",
    "* 10 Cambia el tipo de las variables DST y TZ como categórico.\n",
    "* 11 Obtén un resumen estadístico de las variables categóricas.\n",
    "* 12 Agrupa el dataframe por el tipo de aeropuerto, mostrando el conteo de los tipos.\n",
    "* 13 Selecciona el nombre de las ciudades cuyo tipo de aeropuerto sea \"port\"\n",
    "* 14 Muestra todas las filas de los campos nombre del aeropuerto, nombre del país y, nombre de la ciudad, cuyo país sea Spain.\n",
    "* 15 Muestra el nombre del país y del aeropuerto que sean pertenecientes de la ciudad de Madrid y Barcelona. ¿Todos los registros son de España?\n",
    "* 16 Guarda los resultados anteriores en un csv llamado Madrid_Barcelona.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EN CLASE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
